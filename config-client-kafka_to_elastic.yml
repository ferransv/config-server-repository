#In this file, we will set our configuration properties for the Kafka-to-elastic CONSUMER service, that will be in the config-server repository.
server:
  port: 8182

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  topic-name: twitter-topic
  topic-names-to-create:
    - twitter-topic

#  Kafka consumer config data
kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.LongDeserializer #Since we will read the data from Kafka topic, in the consumer, we need deserializers, to read KEY, which is long...
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer #...and to read value also a deserializer is needed, which is the same Avro type that we defined in the producer
  consumer-group-id: twitter-topic-consumer #property ensures that we do not start from beginning each time, but instead an offset remains for the last read item.
  auto-offset-reset: earliest #We say that we want to start reading from the beginning of a partition.
  specific-avro-reader-key: specific.avro.reader #Since we work with Avro type we have to set this Avro reader property to true in the consumer to true
  specific-avro-reader: true
  batch-listener: true #This property allows to consume the data in batches.
  auto-startup: false # We want to start listening from topic after checking the topic is already there; so auto startup is set to false here. Rather, we will start listening explicitly as it can be seen in the coding section.
  concurrency-level: 3 #Concurrency level is set to three, which is equal to the partition number and it is required for maximum concurrency and higher throughput.
  session-timeout-ms: 10000 #This property is for heartbeat threads and specifies the amount of time within which the brokers needs to get at least one heartbeat signal from the consumer. Otherwise it will mark the consumer as dead. The default value is 10 seconds.
  heartbeat-interval-ms: 3000 #This one specifies the frequency of sending heartbeat signals by the consumer. So if this sets to 3 seconds, which is the default value, then for every 3 seconds the consumer will send the heartbeat signal to the broker.
                              #It is recommended to wait for missing some heartbeat signals before marking the consumer as dead. It is recommended to wait for missing some heartbeat signals before marking the consumer as dead.So it will try three times before timing out.
  max-poll-interval-ms: 300000 #This property is for user threads. If message processing logic is too heavy to cause larger than this time interval, Coordinator explicitly have the consumer leave the group and also triggers a new round of rebalance
  max-poll-records: 500 # It sets the maximum records to fetch in each poll.
  max-partition-fetch-bytes-default: 1048576 #This is the maximum bytes to fetch in each poll.
  max-partition-fetch-bytes-boost-factor: 1
  poll-timeout-ms: 150 #This property determines how long we will wait until at least one record is available. It will block in the poll method on Kafka consumer and wait this time for the new records.
                       #Setting these value to too high will block too much and setting it to too low will cost CPU stall.

#Retry policy as we did with the configuration twitter-to-kafka
retry-config:
  initial-interval-ms: 1000
  max-interval-ms: 10000
  multiplier: 2.0
  maxAttempts: 3
  sleep-time-ms: 2000